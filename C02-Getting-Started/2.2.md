## Exercises

- 2.2-1

> Express the function n3 =1000  100n2  100n C 3 in terms of ‚-notation.

<img src="https://github.com/regalk13/CLRS/blob/main/C02-Getting-Started/2-2-2_IMAGE.png" />

- 2.2-2

> Consider sorting n numbers stored in array A by ﬁrst ﬁnding the smallest element
of A and exchanging it with the element in A[1]. Then ﬁnd the second smallest
element of A, and exchange it with A[2]. Continue in this manner for the ﬁrst n - 1
elements of A. Write pseudocode for this algorithm, which is known as selection
sort. What loop invariant does this algorithm maintain? Why does it need to run
for only the ﬁrst n - 1 elements, rather than for all n elements? Give the best-case
and worst-case running times of selection sort in theta-notation.


**Pseudocode:**

```
Selection-Sort(A)
    for i = 0 to A.length-1
        min_idx = i 
        for j = i+1 to A.length 
            if A[j] < A[min_idx]
                min_idx = j 
        
        A[i], A[min_idx] = A[mind_idx], A[i]
```


**Loop invariant**

- Initialization: We start by showing that the loop invariant holds before loop iteration, when i = 0. 
the sub array A[1..i-1], will be iterated in the innner loop. 

- Maintenance: Each iteration save the index, used to check the condition between the current position and the i..n positions. If this condition is true will be saved the new index. 

- Termination: At the end of the loop the values of the old index and new index are swapped. This sorting the Array in the last iteration. 

**Why does it need to run for only the ﬁrst n - 1 elements, rather than for all n elements?**

It will run for only the first n - 1, because when the  n - 1 elements are sorted. The last element is sorted by consequence.

**Give the best-case and worst-case running times of selection sort in theta-notation.**

Both cases are (n^2). Therefore, the running time of selection sort is always Θ(n^2).


The best-case running time of selection sort is Θ(n^2), where n is the number of elements in the list. This occurs when the list is already sorted or nearly sorted, and the algorithm only needs to perform a small number of comparisons and swaps.

The worst-case running time of selection sort is also Θ(n^2), which occurs when the list is sorted in reverse order. In this case, the algorithm must make n*(n-1)/2 comparisons and n swaps to sort the list.

T(n) = (n-1) + (n-2) + ... + 2 + 1
= n(n-1)/2
= Θ(n^2)

- 2.2-3

> Consider linear search again (see Exercise 2.1-3). How many elements of the in-
put sequence need to be checked on the average, assuming that the element being
searched for is equally likely to be any element in the array? How about in the
worst case? What are the average-case and worst-case running times of linear
search in ‚-notation? Justify your answers.


In linear search, we traverse the array from the beginning to the end, checking each element until we find the element we are searching for or reach the end of the array. If the array has n elements and the element we are searching for is equally likely to be any element in the array, then on average we will need to check half the elements before finding the element we are searching for.

The worst-case scenario in linear search occurs when the element we are searching for is not in the array, and we need to check all n elements in the array before determining that the element is not present.

In big-Theta notation, the worst-case and average-case running times of linear search can be expressed as follows:

- Worst-case: Θ(n) - This is because we may need to check all n elements in the array to determine that the element is not present.


- Average-case: Θ(n/2) = Θ(n) - This is because, on average, we will need to check half the elements before finding the element we are searching for.
Note that the worst-case and average-case running times are the same up to a constant factor, which is why we express them both as Θ(n).

-2.2-4

> How can we modify almost any algorithm to have a good best-case running time?

One way to modify almost any algorithm to have a good best-case running time is to add a check at the beginning of the algorithm to see if the input is already in the desired state or if it is a special case that can be handled separately. If the input is already in the desired state or is a special case, then we can return the result immediately, without executing the rest of the algorithm. This can significantly reduce the running time in the best-case scenario.

For example, let's consider the insertion sort algorithm. The best-case scenario for insertion sort occurs when the input is already sorted. However, the standard implementation of insertion sort does not take advantage of this fact and still performs unnecessary comparisons and swaps.

To modify insertion sort to have a good best-case running time, we can add a check at the beginning of the algorithm to see if the input is already sorted. If it is, we can return the input immediately without executing the rest of the algorithm. This modification reduces the running time of insertion sort to Θ(n) in the best-case scenario.

Of course, not all algorithms can be easily modified in this way, and sometimes the best-case scenario may not be of practical importance. In some cases, it may be more important to optimize the worst-case or average-case running time of an algorithm, even if it comes at the expense of a slightly worse best-case running time.
